{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section must be included at the beginning of each new notebook. Remember to change the app name. \n",
    "# If you're using VirtualBox, change the below to '/home/user/spark-2.1.1-bin-hadoop2.7'\n",
    "import findspark\n",
    "findspark.init('/opt/spark')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('basics').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's read in the data. If you open the dataset, you'll find that each column has a header. We specify that by stating that header=True.\n",
    "# To make our lives easier, we can also use 'inferSchema' when importing CSVs. This automatically detects data types.\n",
    "# If you would like to manually change data types, refer to this article: https://medium.com/@mrpowers/adding-structtype-columns-to-spark-dataframes-b44125409803\n",
    "df = spark.read.csv('Datasets/Accidents_2015.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Accident_Index: string (nullable = true)\n",
      " |-- Location_Easting_OSGR: integer (nullable = true)\n",
      " |-- Location_Northing_OSGR: integer (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Police_Force: integer (nullable = true)\n",
      " |-- Accident_Severity: integer (nullable = true)\n",
      " |-- Number_of_Vehicles: integer (nullable = true)\n",
      " |-- Number_of_Casualties: integer (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Day_of_Week: integer (nullable = true)\n",
      " |-- Time: string (nullable = true)\n",
      " |-- Local_Authority_(District): integer (nullable = true)\n",
      " |-- Local_Authority_(Highway): string (nullable = true)\n",
      " |-- 1st_Road_Class: integer (nullable = true)\n",
      " |-- 1st_Road_Number: integer (nullable = true)\n",
      " |-- Road_Type: integer (nullable = true)\n",
      " |-- Speed_limit: integer (nullable = true)\n",
      " |-- Junction_Detail: integer (nullable = true)\n",
      " |-- Junction_Control: integer (nullable = true)\n",
      " |-- 2nd_Road_Class: integer (nullable = true)\n",
      " |-- 2nd_Road_Number: integer (nullable = true)\n",
      " |-- Pedestrian_Crossing-Human_Control: integer (nullable = true)\n",
      " |-- Pedestrian_Crossing-Physical_Facilities: integer (nullable = true)\n",
      " |-- Light_Conditions: integer (nullable = true)\n",
      " |-- Weather_Conditions: integer (nullable = true)\n",
      " |-- Road_Surface_Conditions: integer (nullable = true)\n",
      " |-- Special_Conditions_at_Site: integer (nullable = true)\n",
      " |-- Carriageway_Hazards: integer (nullable = true)\n",
      " |-- Urban_or_Rural_Area: integer (nullable = true)\n",
      " |-- Did_Police_Officer_Attend_Scene_of_Accident: integer (nullable = true)\n",
      " |-- LSOA_of_Accident_Location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140056"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's read in the data. If you open the dataset, you'll find that each column has a header. We specify that by stating that header=True.\n",
    "# To make our lives easier, we can also use 'inferSchema' when importing CSVs. This automatically detects data types.\n",
    "# If you would like to manually change data types, refer to this article: https://medium.com/@mrpowers/adding-structtype-columns-to-spark-dataframes-b44125409803\n",
    "cdf = spark.read.csv('Datasets/Casualties_2015.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Accident_Index: string (nullable = true)\n",
      " |-- Vehicle_Reference: integer (nullable = true)\n",
      " |-- Casualty_Reference: integer (nullable = true)\n",
      " |-- Casualty_Class: integer (nullable = true)\n",
      " |-- Sex_of_Casualty: integer (nullable = true)\n",
      " |-- Age_of_Casualty: integer (nullable = true)\n",
      " |-- Age_Band_of_Casualty: integer (nullable = true)\n",
      " |-- Casualty_Severity: integer (nullable = true)\n",
      " |-- Pedestrian_Location: integer (nullable = true)\n",
      " |-- Pedestrian_Movement: integer (nullable = true)\n",
      " |-- Car_Passenger: integer (nullable = true)\n",
      " |-- Bus_or_Coach_Passenger: integer (nullable = true)\n",
      " |-- Pedestrian_Road_Maintenance_Worker: integer (nullable = true)\n",
      " |-- Casualty_Type: integer (nullable = true)\n",
      " |-- Casualty_Home_Area_Type: integer (nullable = true)\n",
      " |-- Casualty_IMD_Decile: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186189"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdf = spark.read.csv('Datasets/Vehicles_2015.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257845"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Accident_Index: string (nullable = true)\n",
      " |-- Vehicle_Reference: integer (nullable = true)\n",
      " |-- Vehicle_Type: integer (nullable = true)\n",
      " |-- Towing_and_Articulation: integer (nullable = true)\n",
      " |-- Vehicle_Manoeuvre: integer (nullable = true)\n",
      " |-- Vehicle_Location-Restricted_Lane: integer (nullable = true)\n",
      " |-- Junction_Location: integer (nullable = true)\n",
      " |-- Skidding_and_Overturning: integer (nullable = true)\n",
      " |-- Hit_Object_in_Carriageway: integer (nullable = true)\n",
      " |-- Vehicle_Leaving_Carriageway: integer (nullable = true)\n",
      " |-- Hit_Object_off_Carriageway: integer (nullable = true)\n",
      " |-- 1st_Point_of_Impact: integer (nullable = true)\n",
      " |-- Was_Vehicle_Left_Hand_Drive?: integer (nullable = true)\n",
      " |-- Journey_Purpose_of_Driver: integer (nullable = true)\n",
      " |-- Sex_of_Driver: integer (nullable = true)\n",
      " |-- Age_of_Driver: integer (nullable = true)\n",
      " |-- Age_Band_of_Driver: integer (nullable = true)\n",
      " |-- Engine_Capacity_(CC): integer (nullable = true)\n",
      " |-- Propulsion_Code: integer (nullable = true)\n",
      " |-- Age_of_Vehicle: integer (nullable = true)\n",
      " |-- Driver_IMD_Decile: integer (nullable = true)\n",
      " |-- Driver_Home_Area_Type: integer (nullable = true)\n",
      " |-- Vehicle_IMD_Decile: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vdf.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/david/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: 'select' is deprecated and will be removed in a future release. You can use .loc[labels.map(crit)] as a replacement\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-26fdef57c3ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdrivers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Age_of_Driver\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, crit, axis)\u001b[0m\n\u001b[1;32m   3050\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3051\u001b[0m             new_axis = axis_values[\n\u001b[0;32m-> 3052\u001b[0;31m                 np.asarray([bool(crit(label)) for label in axis_values])]\n\u001b[0m\u001b[1;32m   3053\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3054\u001b[0m             \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3050\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3051\u001b[0m             new_axis = axis_values[\n\u001b[0;32m-> 3052\u001b[0;31m                 np.asarray([bool(crit(label)) for label in axis_values])]\n\u001b[0m\u001b[1;32m   3053\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3054\u001b[0m             \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "drivers=vdf.select(\"Age_of_Driver\")\n",
    "date_time = df.select('Day_of_Week','Time')\n",
    "vdf = drivers.toPandas();\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy import stats\n",
    "#histogram and normal probability plot\n",
    "sns.distplot(vdf['age_of_driver'], fit=norm);\n",
    "fig = plt.figure()\n",
    "res = stats.probplot(df1['age_of_driver'], plot=plt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
